<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>第二周学习周报 |  Phoenix W</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="./favicon.ico" />
       
<link rel="stylesheet" href="/blog/dist/main.css">

      
<link rel="stylesheet" href="/blog/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/blog/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-第二周学习周报"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  第二周学习周报
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/blog/2024/12/07/%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E6%8A%A5/" class="article-date">
  <time datetime="2024-12-06T16:00:00.000Z" itemprop="datePublished">2024-12-07</time>
</a>   
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">1.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">10 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h1><h2 id="1-数据输入"><a href="#1-数据输入" class="headerlink" title="1.数据输入"></a>1.数据输入</h2><p>输入所有数据集的特征向量与标签。</p>
<p>10次10折交叉验证，将数据集划分为训练集、验证集和测试集。</p>
<h2 id="2-算法预测"><a href="#2-算法预测" class="headerlink" title="2.算法预测"></a>2.算法预测</h2><h3 id="决策标准"><a href="#决策标准" class="headerlink" title="决策标准"></a>决策标准</h3><p>三种决策标准:</p>
<h4 id="信息增益值"><a href="#信息增益值" class="headerlink" title="信息增益值"></a>信息增益值</h4><p>D为全体样本，D<sub>i</sub>为某一特征下的各个取值，C<sub>k</sub>为各种标签，A为某一特征。由此可知n为特征下样本的取值个数，K为标签类别数。<br>$$<br>H(D) &#x3D; -\sum_{k&#x3D;1}^K \frac{|C_k|}{|D|}\log_2\frac{|C_k|}{|D|}<br>$$</p>
<p>$$<br>H(D|A)&#x3D;-\sum_{i&#x3D;1}^n \frac{|D_i|}{|D|}\sum_{k&#x3D;1}^K \frac{|D_{ik}|}{|D_i|}\log_2 \frac{|D_{ik}|}{|D_i|}<br>$$</p>
<p>$$<br>g(D,A)&#x3D;H(D)-H(D|A)<br>$$</p>
<p>得出信息增益值 g(D,A)</p>
<h4 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h4><p>适用于特征下取值较多时，用来避免高信息增益而低价值的判断。</p>
<p>$$<br>H_A(D)&#x3D;-\sum_{i&#x3D;1}^n\frac{|D_i|}{|D|}\log_2\frac{|D_i|}{|D|}<br>$$</p>
<p>$$<br>g_R(D,A)&#x3D;\frac{g(D,A)}{H_A(D)}<br>$$</p>
<p>得出信息增益比 g<sub>R</sub>(D,A)</p>
<h4 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h4><p>t某一特征，N<sub>i</sub>代表这个特征下不同标签类别，k为特征的总数。<br>$$<br>p_i&#x3D;\frac{|N_i|}{|N|}<br>$$</p>
<p>$$<br>Gini(t)&#x3D;1-\sum_{i&#x3D;1}^k p_i^2<br>$$</p>
<p>得出基尼指数 Gini(t)</p>
<h4 id="基尼分裂指数"><a href="#基尼分裂指数" class="headerlink" title="基尼分裂指数"></a>基尼分裂指数</h4><p>N<sub>L</sub>为待分裂的左子树，N<sub>R</sub>为待分裂的右子树。<br>$$<br>Gini_{split}&#x3D;\frac{N_L}{N_L+N_R}Gini(L)+\frac{N_L}{N_L+N_R}Gini(R)<br>$$<br>得出基尼分裂指数 Gini<sub>split</sub></p>
<h3 id="生成算法"><a href="#生成算法" class="headerlink" title="生成算法"></a>生成算法</h3><p>三种决策树生成算法：</p>
<h4 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h4><p>以信息增益值为标准，选择信息增益值最大的维度为根节点，递归。</p>
<h4 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h4><p>以信息增益比为标准，选择信息增益比最大的维度为根节点，递归。</p>
<h4 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h4><p>先根据选择基尼指数最小的作为根节点，再通过基尼分裂指数最小的选择分类方式，递归。</p>
<h3 id="剪枝算法"><a href="#剪枝算法" class="headerlink" title="剪枝算法"></a>剪枝算法</h3><h4 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h4><p>当构建决策树时决策信息增益比过小时或基尼指数过大时，直接进行预剪枝，即把子树用用最多的标签代替。</p>
<h4 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h4><p>决策树构建完成后，自下而上进行扫描。若剪枝之后验证集的损失更小，就进行剪枝操作。</p>
<h2 id="3-代码复现"><a href="#3-代码复现" class="headerlink" title="3.代码复现"></a>3.代码复现</h2><h3 id="C4-5算法实现"><a href="#C4-5算法实现" class="headerlink" title="C4.5算法实现"></a>C4.5算法实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_excel</span>(<span class="params">location</span>):</span><br><span class="line">    df = pd.read_excel(location)</span><br><span class="line">    vector = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">    label = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line">    <span class="keyword">return</span> vector, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataset_division</span>(<span class="params">vector, label, num, c</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(label)</span><br><span class="line">    train_vector = []</span><br><span class="line">    train_label = []</span><br><span class="line">    val_vector = []</span><br><span class="line">    val_label = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> i % num != c:</span><br><span class="line">            train_vector.append(vector[i])</span><br><span class="line">            train_label.append(label[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            val_vector.append(vector[i])</span><br><span class="line">            val_label.append(label[i])</span><br><span class="line">    <span class="keyword">return</span> np.array(train_vector), np.array(train_label), np.array(val_vector), np.array(val_label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">label</span>):</span><br><span class="line">    a, counts = np.unique(label, return_counts=<span class="literal">True</span>)</span><br><span class="line">    frac = counts / <span class="built_in">len</span>(label)</span><br><span class="line">    entropy = -np.<span class="built_in">sum</span>(frac * np.log2(frac))</span><br><span class="line">    <span class="keyword">return</span> entropy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_gain_ratio</span>(<span class="params">vector, label, i</span>):</span><br><span class="line">    entropy = cal_entropy(label)</span><br><span class="line">    di, counts = np.unique(vector[:, i], return_counts=<span class="literal">True</span>)</span><br><span class="line">    frac = counts / <span class="built_in">len</span>(vector)</span><br><span class="line">    gain = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(di)):</span><br><span class="line">        son = label[vector[:, i] == di[j]]</span><br><span class="line">        gain -= frac[j] * cal_entropy(son)</span><br><span class="line">    IV = -np.<span class="built_in">sum</span>(frac * np.log2(frac))</span><br><span class="line">    <span class="keyword">if</span> IV == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    ratio = (entropy - gain) / IV</span><br><span class="line">    <span class="keyword">return</span> ratio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tree</span>(<span class="params">vector, label, epsilon=<span class="number">0.01</span>, depth=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(np.unique(label)) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: label[<span class="number">0</span>]&#125;</span><br><span class="line">    <span class="keyword">if</span> vector.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: np.bincount(label).argmax()&#125;  <span class="comment"># Majority class label</span></span><br><span class="line">    max_ratio, max_id = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(vector[<span class="number">0</span>])):</span><br><span class="line">        ratio = cal_gain_ratio(vector, label, i)</span><br><span class="line">        <span class="keyword">if</span> ratio &gt; max_ratio:</span><br><span class="line">            max_ratio = ratio</span><br><span class="line">            max_id = i</span><br><span class="line">    <span class="keyword">if</span> max_ratio &lt; epsilon:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: np.bincount(label).argmax()&#125;  <span class="comment"># Majority class label</span></span><br><span class="line">    values = np.unique(vector[:, max_id])</span><br><span class="line">    decision_tree = &#123;<span class="string">&#x27;point&#x27;</span>: max_id, <span class="string">&#x27;son&#x27;</span>: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> values:</span><br><span class="line">        son_vector = vector[vector[:, max_id] == value]</span><br><span class="line">        son_label = label[vector[:, max_id] == value]</span><br><span class="line">        son_vector = np.delete(son_vector, max_id, axis=<span class="number">1</span>)  <span class="comment"># Remove the used feature</span></span><br><span class="line">        decision_tree[<span class="string">&#x27;son&#x27;</span>][value] = build_tree(son_vector, son_label, epsilon, depth + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> decision_tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search_tree</span>(<span class="params">decision_tree, value</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;label&#x27;</span> <span class="keyword">in</span> decision_tree:</span><br><span class="line">        <span class="keyword">return</span> decision_tree[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        point = decision_tree[<span class="string">&#x27;point&#x27;</span>]</span><br><span class="line">        feature_value = value[point]</span><br><span class="line">        <span class="keyword">if</span> feature_value <span class="keyword">in</span> decision_tree[<span class="string">&#x27;son&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> search_tree(decision_tree[<span class="string">&#x27;son&#x27;</span>][feature_value], value)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.bincount(value.astype(<span class="built_in">int</span>)).argmax()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cut_tree</span>(<span class="params">decision_tree, test_vector, test_label</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;label&#x27;</span> <span class="keyword">in</span> decision_tree:</span><br><span class="line">        <span class="keyword">return</span> decision_tree</span><br><span class="line">    <span class="keyword">for</span> value, subtree <span class="keyword">in</span> decision_tree[<span class="string">&#x27;son&#x27;</span>].items():</span><br><span class="line">        decision_tree[<span class="string">&#x27;son&#x27;</span>][value] = cut_tree(subtree, test_vector, test_label)</span><br><span class="line">    post_label = np.bincount(test_label).argmax()</span><br><span class="line">    pre_error = cal_error(decision_tree, test_vector, test_label)</span><br><span class="line">    post_tree = &#123;<span class="string">&#x27;label&#x27;</span>: post_label&#125;</span><br><span class="line">    post_error = cal_error(post_tree, test_vector, test_label)</span><br><span class="line">    <span class="keyword">if</span> post_error &lt;= pre_error:</span><br><span class="line">        <span class="keyword">return</span> post_tree</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> decision_tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_error</span>(<span class="params">decision_tree, test_vector, test_label</span>):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_vector)):</span><br><span class="line">        <span class="keyword">if</span> search_tree(decision_tree, test_vector[i]) != test_label[i]:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count / <span class="built_in">len</span>(test_vector)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_path = Path(<span class="string">r&quot;E:\Document\MachineLearning\dataset&quot;</span>)</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> base_path.rglob(<span class="string">&#x27;*.xls&#x27;</span>):</span><br><span class="line">    <span class="keyword">if</span> item.is_file():</span><br><span class="line">        result.append(<span class="built_in">str</span>(item))</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">dir</span> <span class="keyword">in</span> result:</span><br><span class="line">    vector, label = read_excel(<span class="built_in">dir</span>)</span><br><span class="line">    start = time.perf_counter()</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train_vector, train_label, test_vector, test_label = dataset_division(vector, label, <span class="number">10</span>, i)</span><br><span class="line">        train_vector, train_label, val_vector, val_label = dataset_division(train_vector, train_label, <span class="number">10</span>, i)</span><br><span class="line">        tree = build_tree(train_vector, train_label, epsilon=<span class="number">0.1</span>)</span><br><span class="line">        tree = cut_tree(tree, test_vector, test_label)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(val_vector)):</span><br><span class="line">            <span class="keyword">if</span> search_tree(tree, val_vector[j]) == val_label[j]:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Dataset **`<span class="subst">&#123;<span class="built_in">dir</span>[-<span class="number">7</span>:-<span class="number">4</span>]&#125;</span>`**, average accuracy: <span class="subst">&#123;count * <span class="number">10</span> / <span class="built_in">len</span>(val_label):<span class="number">.3</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    end = time.perf_counter()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Execution Time: <span class="subst">&#123;end - start:<span class="number">.4</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>运行结果</strong></p>
<blockquote>
<p>Dataset <strong><code>bal</code></strong>, average accuracy: 54.286%<br>Execution Time: 0.1993 seconds<br>Dataset <strong><code>gla</code></strong>, average accuracy: 34.211%<br>Execution Time: 0.3535 seconds<br>Dataset <strong><code>hay</code></strong>, average accuracy: 47.857%<br>Execution Time: 0.0382 seconds<br>Dataset <strong><code>iri</code></strong>, average accuracy: 33.846%<br>Execution Time: 0.0674 seconds<br>Dataset <strong><code>new</code></strong>, average accuracy: 70.000%<br>Execution Time: 0.1220 seconds<br>Dataset <strong><code>win</code></strong>, average accuracy: 39.375%<br>Execution Time: 0.4322 seconds<br>Dataset <strong><code>zoo</code></strong>, average accuracy: 37.778%<br>Execution Time: 0.1743 seconds</p>
</blockquote>
<h3 id="CART算法复现"><a href="#CART算法复现" class="headerlink" title="CART算法复现"></a>CART算法复现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_excel</span>(<span class="params">location</span>):</span><br><span class="line">    df = pd.read_excel(location)</span><br><span class="line">    vector = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">    label = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line">    <span class="keyword">return</span> vector, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataset_division</span>(<span class="params">vector, label, num, c</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(label)</span><br><span class="line">    train_vector = []</span><br><span class="line">    train_label = []</span><br><span class="line">    val_vector = []</span><br><span class="line">    val_label = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> i % num != c:</span><br><span class="line">            train_vector.append(vector[i])</span><br><span class="line">            train_label.append(label[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            val_vector.append(vector[i])</span><br><span class="line">            val_label.append(label[i])</span><br><span class="line">    <span class="keyword">return</span> np.array(train_vector), np.array(train_label), np.array(val_vector), np.array(val_label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_gini</span>(<span class="params">label</span>):</span><br><span class="line">    _, counts = np.unique(label, return_counts=<span class="literal">True</span>)</span><br><span class="line">    frac = counts / <span class="built_in">len</span>(label)</span><br><span class="line">    gini = <span class="number">1</span> - np.<span class="built_in">sum</span>(frac ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> gini</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_gini_index</span>(<span class="params">vector, label, i</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(label)</span><br><span class="line">    best_gini = <span class="number">1000</span></span><br><span class="line">    best_split = <span class="literal">None</span></span><br><span class="line">    best_mask_left = <span class="literal">None</span></span><br><span class="line">    <span class="built_in">sorted</span> = np.sort(np.unique(vector[:, i]))</span><br><span class="line">    splits = (<span class="built_in">sorted</span>[:-<span class="number">1</span>] + <span class="built_in">sorted</span>[<span class="number">1</span>:]) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> split <span class="keyword">in</span> splits:</span><br><span class="line">        left_mask, right_mask = vector[:, i] &lt;= split, vector[:, i] &gt; split</span><br><span class="line">        left_labels, right_labels = label[left_mask], label[right_mask]</span><br><span class="line">        left_gini, right_gini = cal_gini(left_labels), cal_gini(right_labels)</span><br><span class="line">        gini_index = (<span class="built_in">len</span>(left_labels) / n) * left_gini + (<span class="built_in">len</span>(right_labels) / n) * right_gini</span><br><span class="line">        <span class="keyword">if</span> gini_index &lt; best_gini:</span><br><span class="line">            best_gini = gini_index</span><br><span class="line">            best_split = split</span><br><span class="line">            best_mask_left = left_mask</span><br><span class="line">    <span class="keyword">if</span> best_split <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> best_gini, best_split, best_mask_left</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> best_gini, best_split, best_mask_left</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tree</span>(<span class="params">vector, label, epsilon=<span class="number">0.01</span>, depth=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(np.unique(label)) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: label[<span class="number">0</span>]&#125;</span><br><span class="line">    <span class="keyword">if</span> vector.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: np.bincount(label).argmax()&#125;</span><br><span class="line">    min_gini_index = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    best_feature = <span class="literal">None</span></span><br><span class="line">    best_split = <span class="literal">None</span></span><br><span class="line">    best_mask_left = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(vector[<span class="number">0</span>])):</span><br><span class="line">        gini_index, split, mask_left = cal_gini_index(vector, label, i)</span><br><span class="line">        <span class="keyword">if</span> gini_index &lt; min_gini_index:</span><br><span class="line">            min_gini_index = gini_index</span><br><span class="line">            best_feature = i</span><br><span class="line">            best_split = split</span><br><span class="line">            best_mask_left = mask_left</span><br><span class="line">    <span class="keyword">if</span> min_gini_index &gt;= epsilon:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;label&#x27;</span>: np.bincount(label).argmax()&#125;</span><br><span class="line">    left_vector = vector[best_mask_left]</span><br><span class="line">    left_label = label[best_mask_left]</span><br><span class="line">    right_vector = vector[~best_mask_left]</span><br><span class="line">    right_label = label[~best_mask_left]</span><br><span class="line">    decision_tree = &#123;</span><br><span class="line">        <span class="string">&#x27;point&#x27;</span>: best_feature,</span><br><span class="line">        <span class="string">&#x27;split&#x27;</span>: best_split,</span><br><span class="line">        <span class="string">&#x27;son&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;left&#x27;</span>: build_tree(left_vector, left_label, epsilon, depth + <span class="number">1</span>),</span><br><span class="line">            <span class="string">&#x27;right&#x27;</span>: build_tree(right_vector, right_label, epsilon, depth + <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> decision_tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search_tree</span>(<span class="params">decision_tree, value</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;label&#x27;</span> <span class="keyword">in</span> decision_tree:</span><br><span class="line">        <span class="keyword">return</span> decision_tree[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        point = decision_tree[<span class="string">&#x27;point&#x27;</span>]</span><br><span class="line">        feature_value = value[point]</span><br><span class="line">        <span class="keyword">if</span> feature_value &lt;= decision_tree[<span class="string">&#x27;split&#x27;</span>]:</span><br><span class="line">            <span class="keyword">return</span> search_tree(decision_tree[<span class="string">&#x27;son&#x27;</span>][<span class="string">&#x27;left&#x27;</span>], value)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> search_tree(decision_tree[<span class="string">&#x27;son&#x27;</span>][<span class="string">&#x27;right&#x27;</span>], value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_error</span>(<span class="params">decision_tree, test_vector, test_label</span>):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_vector)):</span><br><span class="line">        <span class="keyword">if</span> search_tree(decision_tree, test_vector[i]) != test_label[i]:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count / <span class="built_in">len</span>(test_vector)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_path = Path(<span class="string">r&quot;E:\Document\MachineLearning\dataset&quot;</span>)</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> base_path.rglob(<span class="string">&#x27;*.xls&#x27;</span>):</span><br><span class="line">    <span class="keyword">if</span> item.is_file():</span><br><span class="line">        result.append(<span class="built_in">str</span>(item))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">dir</span> <span class="keyword">in</span> result:</span><br><span class="line">    vector, label = read_excel(<span class="built_in">dir</span>)</span><br><span class="line">    start = time.perf_counter()</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train_vector, train_label, test_vector, test_label = dataset_division(vector, label, <span class="number">10</span>, i)</span><br><span class="line">        train_vector, train_label, val_vector, val_label = dataset_division(train_vector, train_label, <span class="number">10</span>, i)</span><br><span class="line">        tree = build_tree(train_vector, train_label, epsilon=<span class="number">0.9</span>)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(val_vector)):</span><br><span class="line">            <span class="keyword">if</span> search_tree(tree, val_vector[j]) == val_label[j]:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Dataset **`<span class="subst">&#123;<span class="built_in">dir</span>[-<span class="number">7</span>:-<span class="number">4</span>]&#125;</span>`**, average accuracy: <span class="subst">&#123;count * <span class="number">10</span> / <span class="built_in">len</span>(val_label):<span class="number">.3</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    end = time.perf_counter()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Execution Time: <span class="subst">&#123;end - start:<span class="number">.4</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>运行结果</strong></p>
<blockquote>
<p>Dataset <strong><code>bal</code></strong>, average accuracy: 77.857%<br>Execution Time: 0.1870 seconds<br>Dataset <strong><code>gla</code></strong>, average accuracy: 71.053%<br>Execution Time: 1.4938 seconds<br>Dataset <strong><code>hay</code></strong>, average accuracy: 84.286%<br>Execution Time: 0.0395 seconds<br>Dataset <strong><code>iri</code></strong>, average accuracy: 96.154%<br>Execution Time: 0.0880 seconds<br>Dataset <strong><code>new</code></strong>, average accuracy: 94.211%<br>Execution Time: 0.3364 seconds<br>Dataset <strong><code>win</code></strong>, average accuracy: 90.000%<br>Execution Time: 0.9370 seconds<br>Dataset <strong><code>zoo</code></strong>, average accuracy: 96.667%<br>Execution Time: 0.0356 seconds</p>
</blockquote>
<h2 id="4-复盘与分析"><a href="#4-复盘与分析" class="headerlink" title="4.复盘与分析"></a>4.复盘与分析</h2><h3 id="可视化效果"><a href="#可视化效果" class="headerlink" title="可视化效果"></a>可视化效果</h3><p><img src="https://raw.githubusercontent.com/CPhoenixW/blog/refs/heads/gh-pages/images/1-1.png" alt="1-1"></p>
<h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>在CART算法中，将数据特征值当作连续的值先进行排序，后分段可能运用到了数据的连续特征信息，提高了识别的分类的准确率。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/wow/" rel="tag">wow!</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/blog/2024/12/01/%E7%AC%AC%E4%B8%80%E5%91%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E6%8A%A5/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">第一周学习周报</div>
      </a>
    
  </nav>

  
   
  
   
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2024
        <i class="ri-heart-fill heart_icon"></i> Phoenix W
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/blog/"><img src="./images/ayer-side.svg" alt="Phoenix W"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/blog/blog">主页</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/blog/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/blog/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/blog/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/blog/js/jquery-3.6.0.min.js"></script>
 
<script src="/blog/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/blog/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/blog/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.staticfile.org/animejs/3.2.1/anime.min.js"></script>

<script src="/blog/js/clickBoom1.js"></script>
 
<!-- ClickBoom2 -->

<!-- CodeCopy -->

<!-- CanvasBackground -->
 
<script src="/blog/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>