<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>第四周学习周报 |  Phoenix W</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="./favicon.ico" />
       
<link rel="stylesheet" href="/blog/dist/main.css">

      
<link rel="stylesheet" href="/blog/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/blog/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-第四周学习周报"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  第四周学习周报
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/blog/2024/12/28/%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E6%8A%A5/" class="article-date">
  <time datetime="2024-12-27T16:00:00.000Z" itemprop="datePublished">2024-12-28</time>
</a>   
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">2.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">12 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="逻辑斯蒂回归分类（Logistic-Regression）"><a href="#逻辑斯蒂回归分类（Logistic-Regression）" class="headerlink" title="逻辑斯蒂回归分类（Logistic Regression）"></a>逻辑斯蒂回归分类（Logistic Regression）</h1><h2 id="1-数据输入"><a href="#1-数据输入" class="headerlink" title="1.数据输入"></a>1.数据输入</h2><p>输入所有数据集的特征向量与标签。</p>
<p>10次10折交叉验证，将数据集划分为训练集和测试集。</p>
<h2 id="2-算法预测"><a href="#2-算法预测" class="headerlink" title="2.算法预测"></a>2.算法预测</h2><h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>对于某个样本 i，y<sub>k</sub> &#x3D; 1 如果该样本属于类别 k，否则 y<sub>k</sub> &#x3D; 0。</p>
<p>y^k 是模型预测的类别 k 的概率，通过<code>Softmax</code>函数计算得出。</p>
<p>K是类别数。<br>$$<br>L&#x3D;-\sum_{k&#x3D;1}^Ky_k⋅\ln(\hat{y_k})<br>$$<br>Z<sub>i,k</sub>&#x3D;X<sub>i</sub>W<sub>k</sub>+b<sub>k</sub> 是每个样本 i 的类别 k 的逻辑斯蒂加权和。</p>
<p>X<sub>i</sub>是样本 i 的输入特征，W<sub>k</sub>是类别 k 的权重，b<sub>k</sub>是类别 k 的偏置。<br>$$<br>\hat{y_k}&#x3D;\sum_{i&#x3D;1}^N{\frac{e^{Z_{i,k}}}{\sum_{j&#x3D;1}^Ke^{Z_{i,j}}}}<br>$$</p>
<p>$$<br>Z_{i,k}&#x3D;X_iW_k+b_k<br>$$</p>
<h3 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h3><h4 id="通过将L对W求偏导数得出W的梯度："><a href="#通过将L对W求偏导数得出W的梯度：" class="headerlink" title="通过将L对W求偏导数得出W的梯度："></a>通过将L对W求偏导数得出W的梯度：</h4><p>$$<br>\frac{∂L_i}{∂W_k}&#x3D;\frac{∂L_i}{∂Z_{i,k}}⋅\frac{∂Z_{i,k}}{∂W_k}<br>$$</p>
<h5 id="第一项有："><a href="#第一项有：" class="headerlink" title="第一项有："></a>第一项有：</h5><p>$$<br>\frac{∂L_i}{∂Z_{i,k}}&#x3D;\frac{∂L_i}{∂\hat{y_{i,m}}}⋅\frac{∂\hat{y_{i,m}}}{∂Z_{i,k}}&#x3D;\sum_{m&#x3D;1}^K(-\frac{y_{i,m}}{\hat{y_{i,m}}})⋅\hat{y_{i,m}}(δ_{k.m}-\hat{y_{i,m})}&#x3D;\hat{y_{i,k}}-y_{i,k}<br>$$</p>
<p>δ<sub>k,m</sub>代表 k&#x3D;m 时取 1，否则为 0。</p>
<h5 id="第二项有："><a href="#第二项有：" class="headerlink" title="第二项有："></a>第二项有：</h5><p>$$<br>\frac{∂Z_{i,k}}{∂W_k}&#x3D;X_i<br>$$</p>
<h5 id="所以："><a href="#所以：" class="headerlink" title="所以："></a>所以：</h5><p>$$<br>\frac{∂L}{∂W_k}&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N(\hat{y_{i,k}}-y_{i,k})⋅X_i<br>$$</p>
<p>$$<br>\frac{∂L}{∂W}&#x3D;\frac{1}{N}X^T(\hat{y}-y)<br>$$</p>
<h4 id="通过将L对b求偏导数得出偏置b的梯度："><a href="#通过将L对b求偏导数得出偏置b的梯度：" class="headerlink" title="通过将L对b求偏导数得出偏置b的梯度："></a>通过将L对b求偏导数得出偏置b的梯度：</h4><h5 id="同理可得："><a href="#同理可得：" class="headerlink" title="同理可得："></a>同理可得：</h5><p>$$<br>\frac{∂L}{∂b}&#x3D;\frac{1}{N}(\hat{y}-y)<br>$$</p>
<h3 id="梯度下降："><a href="#梯度下降：" class="headerlink" title="梯度下降："></a>梯度下降：</h3><p>每次计算时，将现有权重和偏置减去梯度值，不断梯度下降。</p>
<h2 id="3-代码复现"><a href="#3-代码复现" class="headerlink" title="3.代码复现"></a>3.代码复现</h2><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取Excel数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_excel</span>(<span class="params">location</span>):</span><br><span class="line">    df = pd.read_excel(location)</span><br><span class="line">    vector = df.iloc[:, :-<span class="number">1</span>].values</span><br><span class="line">    label = df.iloc[:, -<span class="number">1</span>].values</span><br><span class="line">    <span class="keyword">return</span> vector, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_data</span>(<span class="params">vector</span>):</span><br><span class="line">    continuous = []</span><br><span class="line">    discrete = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(vector.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> (vector[:, i] == vector[:, i].astype(<span class="built_in">int</span>)).<span class="built_in">all</span>():</span><br><span class="line">            discrete.append(i)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            continuous.append(i)</span><br><span class="line">    <span class="comment"># 离散特征独热化</span></span><br><span class="line">    <span class="keyword">if</span> discrete:</span><br><span class="line">        one_hot_encoder = OneHotEncoder(sparse_output=<span class="literal">False</span>)</span><br><span class="line">        one_hot_encoded = one_hot_encoder.fit_transform(vector[:, discrete])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        one_hot_encoded = np.empty((vector.shape[<span class="number">0</span>], <span class="number">0</span>))</span><br><span class="line">    <span class="comment"># 连续特征规则化</span></span><br><span class="line">    <span class="keyword">if</span> continuous:</span><br><span class="line">        preprocess = vector[:, continuous]</span><br><span class="line">        means = np.mean(preprocess, axis=<span class="number">0</span>)</span><br><span class="line">        stds = np.std(preprocess, axis=<span class="number">0</span>)</span><br><span class="line">        stds[stds == <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        standardized = (preprocess - means) / stds</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        standardized = np.empty((vector.shape[<span class="number">0</span>], <span class="number">0</span>))</span><br><span class="line">    processed_vector = np.hstack((one_hot_encoded, standardized))</span><br><span class="line">    <span class="keyword">return</span> processed_vector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataset_division</span>(<span class="params">vector, label, num, c</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(label)</span><br><span class="line">    train_vector, train_label = [], []</span><br><span class="line">    val_vector, val_label = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> (i % num != c):</span><br><span class="line">            train_vector.append(vector[i])</span><br><span class="line">            train_label.append(label[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            val_vector.append(vector[i])</span><br><span class="line">            val_label.append(label[i])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(train_vector), np.array(val_vector), np.array(train_label), np.array(val_label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, learning_rate=<span class="number">0.01</span>, epochs=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.learning_rate = learning_rate</span><br><span class="line">        <span class="variable language_">self</span>.epochs = epochs</span><br><span class="line">        <span class="variable language_">self</span>.weights = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.biases = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义softmax函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_softmax</span>(<span class="params">self, z</span>):</span><br><span class="line">        exp_z = np.exp(z - np.<span class="built_in">max</span>(z, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>))  <span class="comment"># 防止溢出</span></span><br><span class="line">        <span class="keyword">return</span> exp_z / np.<span class="built_in">sum</span>(exp_z, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义one_hot将标签转化为向量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_one_hot</span>(<span class="params">self, label, num_classes</span>):</span><br><span class="line">        one_hot = np.zeros((label.shape[<span class="number">0</span>], num_classes))</span><br><span class="line">        one_hot[np.arange(label.shape[<span class="number">0</span>]), label] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> one_hot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义模型拟合函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, vector, label</span>):</span><br><span class="line">        num_samples, num_features = vector.shape</span><br><span class="line">        num_classes = np.<span class="built_in">max</span>(label) + <span class="number">1</span></span><br><span class="line">        <span class="variable language_">self</span>.weights = np.random.randn(num_features, num_classes) * <span class="number">0.01</span></span><br><span class="line">        <span class="variable language_">self</span>.biases = np.zeros(num_classes)</span><br><span class="line">        y_one_hot = <span class="variable language_">self</span>._one_hot(label, num_classes)</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        weight = np.zeros((num_features, num_classes))</span><br><span class="line">        <span class="comment"># 梯度下降循环</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.epochs):</span><br><span class="line">            <span class="keyword">if</span> weight.<span class="built_in">all</span>() == <span class="variable language_">self</span>.weights.<span class="built_in">all</span>():</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> count &gt; <span class="variable language_">self</span>.epochs // <span class="number">3</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                weight = <span class="variable language_">self</span>.weights</span><br><span class="line">                count = <span class="number">0</span></span><br><span class="line">            logits = np.dot(vector, <span class="variable language_">self</span>.weights) + <span class="variable language_">self</span>.biases</span><br><span class="line">            y_pred = <span class="variable language_">self</span>._softmax(logits)</span><br><span class="line">            gradient_w = np.dot(vector.T, (y_pred - y_one_hot)) / num_samples</span><br><span class="line">            gradient_b = np.<span class="built_in">sum</span>(y_pred - y_one_hot, axis=<span class="number">0</span>) / num_samples</span><br><span class="line">            <span class="variable language_">self</span>.weights -= <span class="variable language_">self</span>.learning_rate * gradient_w</span><br><span class="line">            <span class="variable language_">self</span>.biases -= <span class="variable language_">self</span>.learning_rate * gradient_b</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测效果</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, vector</span>):</span><br><span class="line">        logits = np.dot(vector, <span class="variable language_">self</span>.weights) + <span class="variable language_">self</span>.biases</span><br><span class="line">        y_pred = <span class="variable language_">self</span>._softmax(logits)</span><br><span class="line">        <span class="keyword">return</span> np.argmax(y_pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model = LogisticRegression(learning_rate=<span class="number">0.1</span>, epochs=<span class="number">10000</span>)</span><br><span class="line">    base_path = Path(<span class="string">r&quot;E:\Document\MachineLearning\dataset&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> base_path.rglob(<span class="string">&#x27;*.xls&#x27;</span>):</span><br><span class="line">        <span class="keyword">if</span> item.is_file():</span><br><span class="line">            dataset_name = item.stem</span><br><span class="line">            vector, label = read_excel(item)</span><br><span class="line">            vector = preprocess_data(vector)</span><br><span class="line">            start = time.perf_counter()</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            <span class="built_in">all</span> = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">                train_vector, val_vector, train_label, val_label = dataset_division(vector, label, num=<span class="number">10</span>, c=i)</span><br><span class="line">                model.fit(train_vector, train_label)</span><br><span class="line">                predictions = model.predict(val_vector)</span><br><span class="line">                count += np.<span class="built_in">sum</span>(predictions == val_label)</span><br><span class="line">                <span class="built_in">all</span> += <span class="built_in">len</span>(val_label)</span><br><span class="line">                acc = np.<span class="built_in">sum</span>(predictions == val_label) / <span class="built_in">len</span>(val_label)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Dataset **`<span class="subst">&#123;dataset_name&#125;</span>`**, epoch <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>, accuracy: <span class="subst">&#123;acc * <span class="number">100</span>:<span class="number">.3</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line">            accuracy = count / <span class="built_in">all</span></span><br><span class="line">            end = time.perf_counter()</span><br><span class="line">            execution_time = end - start</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Dataset **`<span class="subst">&#123;dataset_name&#125;</span>`**, average accuracy: <span class="subst">&#123;accuracy * <span class="number">100</span>:<span class="number">.3</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Execution Time: <span class="subst">&#123;execution_time:<span class="number">.4</span>f&#125;</span> seconds\n&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果</strong></p>
<blockquote>
<p>Dataset <strong><code>bal</code></strong>, epoch 1, accuracy: 98.413%<br>Dataset <strong><code>bal</code></strong>, epoch 2, accuracy: 96.825%<br>Dataset <strong><code>bal</code></strong>, epoch 3, accuracy: 87.302%<br>Dataset <strong><code>bal</code></strong>, epoch 4, accuracy: 98.413%<br>Dataset <strong><code>bal</code></strong>, epoch 5, accuracy: 90.323%<br>Dataset <strong><code>bal</code></strong>, epoch 6, accuracy: 91.935%<br>Dataset <strong><code>bal</code></strong>, epoch 7, accuracy: 95.161%<br>Dataset <strong><code>bal</code></strong>, epoch 8, accuracy: 96.774%<br>Dataset <strong><code>bal</code></strong>, epoch 9, accuracy: 93.548%<br>Dataset <strong><code>bal</code></strong>, epoch 10, accuracy: 98.387%</p>
<p>Dataset <strong><code>bal</code></strong>, average accuracy: 94.712%<br>Execution Time: 12.0552 seconds</p>
<p>Dataset <strong><code>gla</code></strong>, epoch 1, accuracy: 72.727%<br>Dataset <strong><code>gla</code></strong>, epoch 2, accuracy: 63.636%<br>Dataset <strong><code>gla</code></strong>, epoch 3, accuracy: 63.636%<br>Dataset <strong><code>gla</code></strong>, epoch 4, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 5, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 6, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 7, accuracy: 71.429%<br>Dataset <strong><code>gla</code></strong>, epoch 8, accuracy: 71.429%<br>Dataset <strong><code>gla</code></strong>, epoch 9, accuracy: 76.190%<br>Dataset <strong><code>gla</code></strong>, epoch 10, accuracy: 61.905%</p>
<p>Dataset <strong><code>gla</code></strong>, average accuracy: 65.258%<br>Execution Time: 6.9824 seconds</p>
<p>Dataset <strong><code>hay</code></strong>, epoch 1, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 2, accuracy: 75.000%<br>Dataset <strong><code>hay</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>hay</code></strong>, epoch 4, accuracy: 87.500%<br>Dataset <strong><code>hay</code></strong>, epoch 5, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 6, accuracy: 62.500%<br>Dataset <strong><code>hay</code></strong>, epoch 7, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 8, accuracy: 87.500%<br>Dataset <strong><code>hay</code></strong>, epoch 9, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 10, accuracy: 80.000%</p>
<p>Dataset <strong><code>hay</code></strong>, average accuracy: 81.761%<br>Execution Time: 5.5748 seconds</p>
<p>Dataset <strong><code>iri</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 2, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 3, accuracy: 86.667%<br>Dataset <strong><code>iri</code></strong>, epoch 4, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 6, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 7, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 8, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 10, accuracy: 92.857%</p>
<p>Dataset <strong><code>iri</code></strong>, average accuracy: 97.987%<br>Execution Time: 5.1322 seconds</p>
<p>Dataset <strong><code>new</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 2, accuracy: 95.455%<br>Dataset <strong><code>new</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 4, accuracy: 90.909%<br>Dataset <strong><code>new</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 6, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 7, accuracy: 90.476%<br>Dataset <strong><code>new</code></strong>, epoch 8, accuracy: 95.238%<br>Dataset <strong><code>new</code></strong>, epoch 9, accuracy: 90.476%<br>Dataset <strong><code>new</code></strong>, epoch 10, accuracy: 90.476%</p>
<p>Dataset <strong><code>new</code></strong>, average accuracy: 95.327%<br>Execution Time: 7.7811 seconds</p>
<p>Dataset <strong><code>win</code></strong>, epoch 1, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 2, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 3, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 4, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 5, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 6, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 7, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 8, accuracy: 82.353%<br>Dataset <strong><code>win</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 10, accuracy: 100.000%</p>
<p>Dataset <strong><code>win</code></strong>, average accuracy: 95.480%<br>Execution Time: 10.4406 seconds</p>
<p>Dataset <strong><code>zoo</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 2, accuracy: 80.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 4, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 6, accuracy: 90.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 7, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 8, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 10, accuracy: 90.000%</p>
<p>Dataset <strong><code>zoo</code></strong>, average accuracy: 96.000%<br>Execution Time: 5.7426 seconds</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">epoach = <span class="number">50000</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Dataset <strong><code>bal</code></strong>, epoch 1, accuracy: 98.413%<br>Dataset <strong><code>bal</code></strong>, epoch 2, accuracy: 95.238%<br>Dataset <strong><code>bal</code></strong>, epoch 3, accuracy: 85.714%<br>Dataset <strong><code>bal</code></strong>, epoch 4, accuracy: 96.825%<br>Dataset <strong><code>bal</code></strong>, epoch 5, accuracy: 88.710%<br>Dataset <strong><code>bal</code></strong>, epoch 6, accuracy: 87.097%<br>Dataset <strong><code>bal</code></strong>, epoch 7, accuracy: 95.161%<br>Dataset <strong><code>bal</code></strong>, epoch 8, accuracy: 95.161%<br>Dataset <strong><code>bal</code></strong>, epoch 9, accuracy: 93.548%<br>Dataset <strong><code>bal</code></strong>, epoch 10, accuracy: 95.161%</p>
<p>Dataset <strong><code>bal</code></strong>, average accuracy: 93.109%<br>Execution Time: 12.6704 seconds</p>
<p>Dataset <strong><code>gla</code></strong>, epoch 1, accuracy: 68.182%<br>Dataset <strong><code>gla</code></strong>, epoch 2, accuracy: 59.091%<br>Dataset <strong><code>gla</code></strong>, epoch 3, accuracy: 68.182%<br>Dataset <strong><code>gla</code></strong>, epoch 4, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 5, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 6, accuracy: 57.143%<br>Dataset <strong><code>gla</code></strong>, epoch 7, accuracy: 76.190%<br>Dataset <strong><code>gla</code></strong>, epoch 8, accuracy: 71.429%<br>Dataset <strong><code>gla</code></strong>, epoch 9, accuracy: 76.190%<br>Dataset <strong><code>gla</code></strong>, epoch 10, accuracy: 57.143%</p>
<p>Dataset <strong><code>gla</code></strong>, average accuracy: 64.789%<br>Execution Time: 7.1636 seconds</p>
<p>Dataset <strong><code>hay</code></strong>, epoch 1, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 2, accuracy: 75.000%<br>Dataset <strong><code>hay</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>hay</code></strong>, epoch 4, accuracy: 87.500%<br>Dataset <strong><code>hay</code></strong>, epoch 5, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 6, accuracy: 62.500%<br>Dataset <strong><code>hay</code></strong>, epoch 7, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 8, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 9, accuracy: 81.250%<br>Dataset <strong><code>hay</code></strong>, epoch 10, accuracy: 73.333%</p>
<p>Dataset <strong><code>hay</code></strong>, average accuracy: 80.503%<br>Execution Time: 5.8169 seconds</p>
<p>Dataset <strong><code>iri</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 2, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 3, accuracy: 86.667%<br>Dataset <strong><code>iri</code></strong>, epoch 4, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 6, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 7, accuracy: 93.333%<br>Dataset <strong><code>iri</code></strong>, epoch 8, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>iri</code></strong>, epoch 10, accuracy: 92.857%</p>
<p>Dataset <strong><code>iri</code></strong>, average accuracy: 97.315%<br>Execution Time: 5.2833 seconds</p>
<p>Dataset <strong><code>new</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 2, accuracy: 95.455%<br>Dataset <strong><code>new</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 4, accuracy: 90.909%<br>Dataset <strong><code>new</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 6, accuracy: 100.000%<br>Dataset <strong><code>new</code></strong>, epoch 7, accuracy: 90.476%<br>Dataset <strong><code>new</code></strong>, epoch 8, accuracy: 95.238%<br>Dataset <strong><code>new</code></strong>, epoch 9, accuracy: 90.476%<br>Dataset <strong><code>new</code></strong>, epoch 10, accuracy: 90.476%</p>
<p>Dataset <strong><code>new</code></strong>, average accuracy: 95.327%<br>Execution Time: 7.8368 seconds</p>
<p>Dataset <strong><code>win</code></strong>, epoch 1, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 2, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 3, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 4, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 5, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 6, accuracy: 94.444%<br>Dataset <strong><code>win</code></strong>, epoch 7, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 8, accuracy: 82.353%<br>Dataset <strong><code>win</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>win</code></strong>, epoch 10, accuracy: 100.000%</p>
<p>Dataset <strong><code>win</code></strong>, average accuracy: 95.480%<br>Execution Time: 10.4644 seconds</p>
<p>Dataset <strong><code>zoo</code></strong>, epoch 1, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 2, accuracy: 80.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 3, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 4, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 5, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 6, accuracy: 90.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 7, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 8, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 9, accuracy: 100.000%<br>Dataset <strong><code>zoo</code></strong>, epoch 10, accuracy: 90.000%</p>
<p>Dataset <strong><code>zoo</code></strong>, average accuracy: 96.000%<br>Execution Time: 5.4742 seconds</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.05</span></span><br><span class="line">epoach = <span class="number">50000</span></span><br></pre></td></tr></table></figure>

<h2 id="4-复盘与分析"><a href="#4-复盘与分析" class="headerlink" title="4.复盘与分析"></a>4.复盘与分析</h2><p>感觉<code>LearningRate</code>和<code>epoach</code>对准确度的影响好像没那么大。</p>
<p>当模型参数长时间不再优化时提前结束可以大大提高效率，并且对总体影响不大。</p>
<p><img src="https://raw.githubusercontent.com/CPhoenixW/blog/refs/heads/gh-pages/images/4-1.png" alt="4-1"></p>
<p>区分连续变量和离散变量对整体运行结果有很大提升。</p>
<p><img src="https://github.com/CPhoenixW/blog/blob/gh-pages/images/4-2.png?raw=true" alt="4-2"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/blog/2025/01/11/%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E6%8A%A5/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            第五周学习周报
          
        </div>
      </a>
    
    
      <a href="/blog/2024/12/21/%E7%AC%AC%E4%B8%89%E5%91%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E6%8A%A5/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">第三周学习周报</div>
      </a>
    
  </nav>

  
   
  
   
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2024-2025
        <i class="ri-heart-fill heart_icon"></i> Phoenix W
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/blog/"><img src="./images/ayer-side.svg" alt="Phoenix W"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/blog/blog">主页</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/blog/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/blog/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/blog/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/blog/js/jquery-3.6.0.min.js"></script>
 
<script src="/blog/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/blog/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/blog/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.css">
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.js"></script>
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/contrib/auto-render.min.js"></script>
        
    
 
<!-- busuanzi  -->
 
<script src="/blog/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->

<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>